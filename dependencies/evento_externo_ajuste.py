from pyspark.sql.types import *

bq_table_name = "evento_externo_ajuste"
columns_type = {
	"hash_key": StringType,
	"source": StringType,
	"ea_id_eventoajuste": IntegerType,
	"ea_id_movimentoajuste": IntegerType,
	"ea_id_tipoajuste": IntegerType,
	"ea_datainclusao": TimestampType,
	"ea_dataorigem": TimestampType,
	"ea_datamovimento": TimestampType,
	"ea_id_conta": IntegerType,
	"ea_valor": DoubleType,
	"ea_sequencialcartao": IntegerType,
	"ea_datavencimentopadrao": StringType,
	"ea_datavencimentoreal": TimestampType,
	"ea_id_estabelecimento": IntegerType,
	"ea_id_transacaooriginal": LongType,
	"ea_status": IntegerType,
	"ea_responsavelinclusao": StringType,
	"ea_dataprocessamentolojista": TimestampType,
	"ea_id_borderaux": IntegerType,
	"ea_dataprocessamentolojista2": TimestampType,
	"ea_id_eventoexternooriginal": IntegerType,
	"ea_tipoeventoexternooriginal": StringType,
	"ea_statuslojista": IntegerType,
	"ea_id_estabelecimento_visa": IntegerType,
	"ea_valordestino": DoubleType,
	"ea_id_incoming": IntegerType,
	"ea_parcelapedidaincoming": IntegerType,
	"ea_origemresolucao": StringType,
	"ea_datavencpadrao": TimestampType,
	"ea_datadebitoconta": TimestampType,
	"ea_descricaoestabelecimentoexterno": StringType,
	"dh_relatorio": TimestampType,
	"operation": StringType,
	"operation_sequence": IntegerType,
	"production_date": DateType,
}
